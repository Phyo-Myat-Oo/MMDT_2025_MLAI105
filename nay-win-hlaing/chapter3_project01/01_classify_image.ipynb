{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "## Image Classification Using Known CNN Models\n",
    "\n",
    "### Overview\n",
    "\n",
    "In this project, we classify images using five well-known Convolutional Neural Network (CNN) models implemented with the Python `keras` library. The models used are `ResNet50`, `VGG16`, `InceptionV3`, `Xception`, and `EfficientNetB7`. The goal is to load an image, pass it through each of these models, and obtain the top prediction for the image. This project consists of two Python scripts: one for defining the CNN models (`cnn_models.py`) and one main script (`main.py`) for classifying an image.\n",
    "\n",
    "### Project Components\n",
    "\n",
    "#### 1. `cnn_models.py`\n",
    "\n",
    "This script defines a class, `cnnModels`, which provides an interface to load and use the pre-trained CNN models. The class includes methods for initializing models, retrieving models by name, and classifying images.\n",
    "\n",
    "##### `cnnModels` Class\n",
    "\n",
    "- **`__init__(self)`**: Initializes the class and loads the pre-trained models.\n",
    "- **`resnet(self)`**: Loads and returns the `ResNet50` model with ImageNet weights.\n",
    "- **`vggnet(self)`**: Loads and returns the `VGG16` model with ImageNet weights.\n",
    "- **`inception(self)`**: Loads and returns the `InceptionV3` model with ImageNet weights.\n",
    "- **`convnet(self)`**: Loads and returns the `Xception` model with ImageNet weights.\n",
    "- **`efficientnet(self)`**: Loads and returns the `EfficientNetB7` model with ImageNet weights.\n",
    "- **`get_model(self, name)`**: Retrieves a model by name from the dictionary of models.\n",
    "- **`classify_image(self, name, img)`**: Classifies an image using the specified model and returns the top 3 predictions.\n",
    "\n",
    "#### 2. `main.ipynb`\n",
    "\n",
    "This script demonstrates how to use the `cnnModels` class to classify an image.\n",
    "\n",
    "##### Example Usage\n",
    "\n",
    "```python\n",
    "from cnn_models import cnnModels\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "# Specify the image path\n",
    "img_path = './imgs/dog.jpeg'\n",
    "img = load_img(img_path)\n",
    "\n",
    "# Initialize the cnnModels class\n",
    "model = cnnModels()\n",
    "\n",
    "# Classify the image using ResNet50\n",
    "preds1 = model.classify_image('ResNet50', img)\n",
    "\n",
    "# Print the top predictions\n",
    "for pred in preds1:\n",
    "    print(f\"{pred[1]}: {pred[2]}, {pred[3]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state-of-the-art CNN models are tested using two datasets: \n",
    "1) AI-generated Images that contains 10 images\n",
    "2) 10 Real Images collected from the internet\n",
    "\n",
    "average accuracy, precision and recall scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cnn_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcnn_models\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_img \u001b[38;5;66;03m#type: ignore\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cnn_models'"
     ]
    }
   ],
   "source": [
    "import cnn_models\n",
    "import pandas as pd\n",
    "from keras.utils import load_img #type: ignore\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002717D756FC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 50 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000027187A88E00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def get_predictions(image_dir):\n",
    "    model = cnn_models.cnnModels()\n",
    "    model_names = ['ResNet50', 'VGGNet16', 'InceptionV3', 'ConvNeXt', 'EfficientNet']\n",
    "    \n",
    "    # Prepare DataFrame columns\n",
    "    columns = []\n",
    "    for name in model_names:\n",
    "        columns.extend([f\"{name}_pred{i}\" for i in range(1,4)] + \n",
    "                      [f\"{name}_prob{i}\" for i in range(1,4)] +\n",
    "                      [f\"{name}_time\"])  # Add time column for each model\n",
    "    \n",
    "    columns.append('label')\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.lower().endswith(('.jpeg', '.png', '.jpg')):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            img = load_img(image_path)\n",
    "            label = filename.split('.')[0]\n",
    "            \n",
    "            row = {'label': label}\n",
    "            \n",
    "            for name in model_names:\n",
    "                start_time = time.time()  # Start timer\n",
    "                preds = model.classify_image(name, img)\n",
    "                end_time = time.time()   # End timer\n",
    "                \n",
    "                inference_time = end_time - start_time\n",
    "                row[f\"{name}_time\"] = inference_time  # Store inference time\n",
    "                \n",
    "                for i, pred in enumerate(preds[0], start=1):\n",
    "                    row[f\"{name}_pred{i}\"] = pred[1]  # Class name\n",
    "                    row[f\"{name}_prob{i}\"] = pred[2]  # Probability\n",
    "            \n",
    "            results.append(row)\n",
    "    \n",
    "    return pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Get predictions\n",
    "fake_dir = './dataset/synthetic1/'\n",
    "real_dir = './dataset/real1/'\n",
    "    \n",
    "real_result = get_predictions(real_dir)\n",
    "fake_result = get_predictions(fake_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "real_result.to_csv('./results/real_result_top3_with_time.csv', index=False)\n",
    "fake_result.to_csv('./results/fake_result_top3_with_time.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
