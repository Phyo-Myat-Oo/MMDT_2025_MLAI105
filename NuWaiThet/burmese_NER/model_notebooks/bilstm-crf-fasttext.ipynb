{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d3a7e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from TorchCRF import CRF\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9710c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 1. Load CoNLL file\n",
    "# -----------------------\n",
    "def load_conll(file_path):\n",
    "    \"\"\"\n",
    "    Load a CoNLL file and return sentences and NER labels.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CoNLL file.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[List[str]], List[List[str]]]:\n",
    "            - sentences: List of sentences, each sentence is a list of tokens.\n",
    "            - labels: List of NER tag sequences, each is a list of tags.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentence, ner_tags = [], []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    labels.append(ner_tags)\n",
    "                    sentence, ner_tags = [], []\n",
    "            else:\n",
    "                parts = line.split(\"\\t\")\n",
    "                if len(parts) != 3:\n",
    "                    continue\n",
    "                token, _, ner = parts\n",
    "                sentence.append(token)\n",
    "                ner_tags.append(ner)\n",
    "        if sentence:\n",
    "            sentences.append(sentence)\n",
    "            labels.append(ner_tags)\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afc0a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 2. Load FastText embeddings\n",
    "# -----------------------\n",
    "ft_model = KeyedVectors.load(\"fasttext_gensim.model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4f2719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014775803\n",
      "0.34179795\n",
      "[-0.44198282  0.02582968  0.33800261  0.06594879 -0.44878828  0.47088423\n",
      " -0.27932665  0.42560581 -0.05572311  0.4001316   0.13055134 -0.11151295\n",
      " -0.15306171 -0.14323097 -0.12913796  0.26138182 -0.63468155 -0.11789568\n",
      "  0.65389852 -0.74062469  0.42172738 -0.11889626  0.23699606 -0.02890524\n",
      "  0.35524373  0.02966917 -0.43205671 -0.37794963  0.00752425  0.49174917\n",
      " -0.47561019 -0.5359647  -0.25842451 -0.54694707  0.25038778  0.22674871\n",
      " -0.00955855 -0.27833973  0.34721668 -0.15114986 -0.0874848   0.25236214\n",
      " -0.30786855 -0.33711216  0.76460319  0.35511871  0.06550735  0.18226581\n",
      "  0.58270976 -0.50396422 -0.04041729  0.24810192 -0.51318792  0.22582641\n",
      " -0.22378568  0.5351447   0.26858919  0.21304395 -0.18398857 -0.28159121\n",
      "  0.69626335  0.34860435 -0.09992923  0.19538345 -0.55617664 -0.03142043\n",
      "  0.30947933  0.03735474 -0.04113931  0.53330784 -0.249353   -0.1070699\n",
      "  0.03153271 -0.22676216 -0.94700628 -0.65426211 -0.09662536  0.15883235\n",
      "  0.04005759 -0.42273942 -0.01607437 -0.34438798 -0.39750211  0.75884126\n",
      " -0.07391604  0.37812354 -0.16638782 -0.07235435  0.11739932  0.00329768\n",
      " -0.31127502 -0.38648332 -0.02455068  0.10292985  0.12949233 -0.19359058\n",
      " -0.47252779 -0.20042996 -0.54134175 -0.65628549 -0.19349168 -0.32150308\n",
      "  0.11324399  0.1667649  -0.35303649 -0.30790681  0.26511086 -0.49205684\n",
      " -0.34435766  0.30967915 -0.33290847  0.10112839  0.03285791 -0.1321344\n",
      "  0.17388354  0.14207141 -0.03647757  0.09058885  0.29152337  0.08996235\n",
      " -0.6119844   0.11716829  0.43131602  0.32318357 -0.53066882  0.58815375\n",
      " -0.22472159 -0.31721802  0.2680831  -0.61380623 -0.15770744  0.35467311\n",
      " -0.21783334 -0.05032193 -0.54408367  0.45500016  0.1938789  -0.24450935\n",
      "  0.02772618  0.82457904 -0.26682207  0.27560856 -0.30952104 -0.49102339\n",
      "  0.07556376 -0.13919549 -0.54437881  0.08468675 -0.00701229 -0.48682606\n",
      " -0.25454352 -0.37638575  0.31134118 -0.16246258 -0.21790939 -0.57273499\n",
      " -0.01383748  0.04415612  0.47006511 -0.29254598 -0.16063535  0.55189636\n",
      "  0.01732769 -0.23289097 -0.19494533  0.82095151 -0.03061022 -0.49071301\n",
      " -0.59023294  0.03381268 -0.13391086 -0.07270247  0.49245115 -0.13822859\n",
      " -0.14893341 -0.32454233 -0.30152306  0.50265929 -0.07671953 -0.09035722\n",
      "  0.00682959  0.41480446  0.16691501  0.30917121  0.29027884  0.41272049\n",
      " -0.32695623  0.0557361  -0.6275742  -0.51431554 -0.80306129 -0.28044047\n",
      "  0.11551597  0.03491153 -0.02427567  0.50174915 -0.37002497 -0.2534941\n",
      " -0.24753967  0.1129453   0.13598114 -0.06846972 -0.59874564 -0.28885478\n",
      "  0.12103608  0.13026807 -0.68314636  0.33844424  0.18486692 -0.16326156\n",
      " -0.27765612  0.02646119 -0.03164784 -0.03417556 -0.01207692 -0.07579389\n",
      "  0.21416134 -0.37069083 -0.51498604  1.07526006  0.64384116  0.2411433\n",
      "  0.35425896 -0.05566582 -0.17467919 -0.29274094 -0.16316957 -0.01563491\n",
      "  0.18868337  0.24852748  0.00659251  0.11654785  0.3339567   0.2263825\n",
      "  0.43009574 -0.3043961  -0.08712476 -0.34405462  0.33723057  0.31866997\n",
      "  0.42569544  0.11031388 -0.15900083 -0.14656193 -0.25530968 -0.43254059\n",
      " -0.05862945 -0.33232352 -0.27872946  0.43543509 -0.23416332  0.27903815\n",
      "  0.13921375 -0.94648715 -0.15312849 -0.5430496  -0.36949609  0.3493377\n",
      "  0.35347051  0.19711408 -0.19329311  0.48829154 -0.26926347 -0.71328442\n",
      " -0.14140273  0.11157194 -0.41392268 -0.2893044   0.1934915   0.34779191\n",
      "  0.05142338  0.16617832 -0.02162044 -0.17643406  0.22506341  0.13315604\n",
      " -0.46215117  0.21378915 -0.20043524 -0.02010854 -0.12042952  0.10902943\n",
      " -0.04701368 -0.67958721 -0.33786878 -0.0821716   0.10690063 -0.03619598\n",
      "  0.05402256  0.40643777  0.59532093 -0.59120521 -0.61507091  0.22319114\n",
      "  0.26637252  0.13809241  0.13683842  0.00580477  0.22714355  0.19470708]\n"
     ]
    }
   ],
   "source": [
    "mean = ft_model.wv.vectors.mean()\n",
    "std = ft_model.wv.vectors.std()\n",
    "print(mean)\n",
    "print(std)\n",
    "print(np.random.normal(mean, std, size=ft_model.vector_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82f6208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: 'O', 2: 'B-LOC', 3: 'I-LOC', 4: 'B-DATE', 5: 'I-DATE', 6: 'B-TIME', 7: 'I-TIME'}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 3. Prepare vocab and tag mappings\n",
    "# -----------------------\n",
    "sentences, labels = load_conll(\"ner_80train.conll\")  # load training file\n",
    "\n",
    "# Word vocab: use index lookup for embedding layer\n",
    "# eg: vocab = {\"<PAD>\":0, \"<UNK>\":1, \"John\":2, \"lives\":3, \"in\":4, \"Yangon\":5,}\n",
    "# Word embeddings lookup (vocab)\n",
    "# NER label lookup (ner_tag_to_ix and id2tag)\n",
    "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for sent in sentences:  # word-to-index mapping to feed words into an embedding layer\n",
    "    for w in sent:\n",
    "        if w not in vocab:\n",
    "            vocab[w] = len(vocab) # new word the next available integer ID, to ensure unique, sequential indices\n",
    "\n",
    "# NER tag mapping\n",
    "ner_tag_to_ix = {\"<PAD>\": 0}\n",
    "for tag_seq in labels:\n",
    "    for t in tag_seq:\n",
    "        if t not in ner_tag_to_ix:\n",
    "            ner_tag_to_ix[t] = len(ner_tag_to_ix)\n",
    "id2tag = {v: k for k, v in ner_tag_to_ix.items()}\n",
    "print(id2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaf3a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 4. Dataset with dynamic padding\n",
    "# -----------------------\n",
    "class NERDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for Burmese NER.\n",
    "\n",
    "    Args:\n",
    "        sentences (List[List[str]]): List of sentences (tokenized).\n",
    "        labels (List[List[str]]): List of NER tag sequences.\n",
    "        vocab (dict): Mapping from token to index.\n",
    "        ner_tag_to_ix (dict): Mapping from NER tag to index.\n",
    "    output:\n",
    "        ([\"token1\", \"token2\", ..., \"tokenN\"], [\"label1\", \"label2\", ..., \"labelN\"])\n",
    "    \"\"\"\n",
    "    def __init__(self, sentences, labels, vocab, ner_tag_to_ix):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.ner_tag_to_ix = ner_tag_to_ix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sentences[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2feaa448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function for dynamic padding in DataLoader.\n",
    "\n",
    "    Args:\n",
    "        batch (List[Tuple[List[str], List[str]]]): Batch of sentences and NER tags.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Tensor, Tensor]: Padded token indices and tag indices.\n",
    "    Steps:\n",
    "    1. Receives a batch of sentences and their corresponding NER tag sequences.\n",
    "    2. Finds the length of the longest sentence in the batch.\n",
    "    3. Pads all sentences and tag sequences to this maximum length using \"<PAD>\".\n",
    "    4. Converts words to their corresponding indices from `vocab` (unknown words get \"<UNK>\").\n",
    "    5. Converts NER tags to their corresponding indices from `ner_tag_to_ix`.\n",
    "    6. Returns two PyTorch tensors: (Shape: (batch_size, max_len))\n",
    "   - Padded token indices: shape (batch_size, max_len)\n",
    "   - Padded tag indices: shape (batch_size, max_len)\n",
    "    \"\"\"\n",
    "    sentences, ner_tags = zip(*batch)\n",
    "    max_len = max(len(s) for s in sentences)\n",
    "\n",
    "    sent_idxs = []\n",
    "    tag_idxs = []\n",
    "\n",
    "    for s, t in zip(sentences, ner_tags):\n",
    "        padded_s = s + [\"<PAD>\"] * (max_len - len(s))\n",
    "        padded_t = t + [\"<PAD>\"] * (max_len - len(t))\n",
    "        sent_idxs.append([vocab.get(w, vocab[\"<UNK>\"]) for w in padded_s])\n",
    "        tag_idxs.append([ner_tag_to_ix[tag] for tag in padded_t])\n",
    "\n",
    "    return torch.tensor(sent_idxs, dtype=torch.long), torch.tensor(tag_idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b56777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: ['·Äû·Ä∞', '·Äê·Ä≠·ÄØ·Ä∑', '·Äû·Ää·Ä∫', '·Äû·Ä±·Äí·Äè·Ä∫', '·ÄÄ·Ä≠·ÄØ', '·Äõ·ÄÑ·Ä∫', '·ÄÜ·Ä≠·ÄØ·ÄÑ·Ä∫', '·Äõ', '·Äô·Ää·Ä∫', '·ÄÄ·Ä≠·ÄØ', '·Äû·Ä≠', '·ÄÅ·Ä≤·Ä∑', '·Äû·Ä±·Ä¨', '·Äî·Ä±', '·Äõ·Ä¨', '·Åä', '·Ä°·ÄÑ·Ä∫·Äí·Ä≠·ÄØ·Ä∏·Äî·ÄÆ·Ä∏·Äõ·Äæ·Ä¨·Ä∏', '·Äû·Ä≠·ÄØ·Ä∑', '·ÄÅ·Äõ·ÄÆ·Ä∏·Äû·ÄΩ·Ä¨·Ä∏', '·Äõ·Äî·Ä∫', '·Äò·Ä¨·Äú·ÄÆ', '·Äî·Ä≠·ÄØ·ÄÑ·Ä∫·Ä∏', '·ÄÄ·Ä≠·ÄØ', '·ÄÅ·ÄΩ·ÄÑ·Ä∫·Ä∑·Äï·Äº·ÄØ', '·ÄÅ·Äº·ÄÑ·Ä∫·Ä∏', '·Ä°·Äê·ÄΩ·ÄÄ·Ä∫', '·Ä©·ÄÖ·Äê·Äº·Ä±·Ä∏·Äú·Äª', '·Äñ·Äö·Ä∫·Äí·Äõ·Äö·Ä∫', '·Äõ·Ä≤·Äê·Äï·Ä∫·Äñ·ÄΩ·Ä≤·Ä∑', '·Äû·Ää·Ä∫', '·Äù·Ä±·Äñ·Äî·Ä∫', '·ÄÅ·Ä∂', '·ÄÅ·Ä≤·Ä∑', '·Äõ', '·Äû·Ää·Ä∫', '·Åã']\n",
      "Label: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Sentences batch: tensor([[  623,   339,  9956,    18,  2664,     3,  2464,  1243,    95,   170,\n",
      "            27,    29,  2464,   249,    86,    95,    44,   146,  1994,    92,\n",
      "            46,   496,  5692,    58, 19262,  7241,    58, 10078,   208,   325,\n",
      "          1003,    63,    22,  9448,   293,    95,  1374,   116,   525,  1114,\n",
      "          1521, 17736,    39,    89,   227,   250,  1748,   125,     3,  1096,\n",
      "          2518,  1811,  2340,  1602,    28,     3,    91,    53,     6,     8],\n",
      "        [ 1925,   587,   291,   957,    18,   268,    77,    66,    44,   823,\n",
      "           824,   227,    68,    58,    60,   625, 13994,     3,    58,  4773,\n",
      "            93,  3933,    24,  1192,    50,    43,   263,   372,    24,   339,\n",
      "            44, 13579,  1837,    92,    93,   488,    51,    92,    93,     8,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [13797,   777,   206,   307,  1845,   293,  1593,  1469,   780,   213,\n",
      "           161,    79,    66,  2119,  2247,    68,   777,  1094,    66,    44,\n",
      "           702,   713,   347,  2201,   183,    28,    93,    18,    70,  1058,\n",
      "          2230,  4028,   159,   148,   612,  1058,  2230,   777,    61,    46,\n",
      "           293,   235,   227,    93,     8,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  391,  2125,  1083,   138,     3,  1110,    97,  2874,    44,   870,\n",
      "           296,   180,   402,   261,    47,    51,    91,   255,   410,   116,\n",
      "            33,    58,   229,  1944,  1527,     3,    58,    51,   255,    92,\n",
      "            93,     8,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n",
      "Labels batch: tensor([[1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [6, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# check dataset sample\n",
    "batch_size = 4\n",
    "\n",
    "dataset = NERDataset(sentences, labels, vocab, ner_tag_to_ix)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "sentence, label = dataset[6]\n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(f\"Label: {label}\")\n",
    "\n",
    "for batch in loader:\n",
    "    sentences, labels = batch\n",
    "    print(\"Sentences batch:\", sentences)\n",
    "    print(\"Labels batch:\", labels)\n",
    "    break   # stop after first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d33d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 4325.9877\n",
      "Epoch 2/10, Loss: 1569.9689\n",
      "Epoch 3/10, Loss: 1145.7503\n",
      "Epoch 4/10, Loss: 920.1621\n",
      "Epoch 5/10, Loss: 761.4495\n",
      "Epoch 6/10, Loss: 641.9766\n",
      "Epoch 7/10, Loss: 538.4350\n",
      "Epoch 8/10, Loss: 449.4353\n",
      "Epoch 9/10, Loss: 379.2052\n",
      "Epoch 10/10, Loss: 319.4638\n",
      "Training completed in 3808.49 seconds\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 5. BiLSTM-CRF Model\n",
    "# -----------------------\n",
    "class BiLSTM_CRF(nn.Module):\n",
    "    \"\"\"\n",
    "    BiLSTM-CRF model for sequence labeling with FastText embeddings.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of vocabulary.\n",
    "        embedding_dim (int): Dimension of embeddings.\n",
    "        hidden_dim (int): Hidden size of LSTM.\n",
    "        tagset_size (int): Number of NER tags.\n",
    "        ft_model (KeyedVectors): Pretrained FastText embeddings.\n",
    "    Steps:\n",
    "        1. Create an embedding layer to map word indices ‚Üí vectors.\n",
    "        2. Initialize embeddings from pretrained FastText:\n",
    "        - Use FastText vector if available.\n",
    "        - Otherwise, use a random vector.\n",
    "        3. Create a bidirectional LSTM to capture context from both directions.\n",
    "        4. Add a linear layer to map LSTM outputs ‚Üí tag scores.\n",
    "        5. Add a CRF layer to model valid tag transitions and sequence-level predictions.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, tagset_size, ft_model):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Initialize embedding weights from FastText\n",
    "        emb_weights = np.zeros((vocab_size, embedding_dim))\n",
    "        for w, idx in vocab.items():\n",
    "            if w in ft_model.wv:            \n",
    "                emb_weights[idx] = ft_model.wv[w]\n",
    "            else:\n",
    "                emb_weights[idx] = np.random.normal(scale=0.6, size=(embedding_dim,)) # scale = standard deviation (spread) of the distribution.\n",
    "        self.embedding.weight.data.copy_(torch.tensor(emb_weights, dtype=torch.float32))\n",
    "        \n",
    "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                              num_layers=1, bidirectional=True, batch_first=True) # batch_first=True, batch_size, seq_len, input_size\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.crf = CRF(tagset_size, batch_first=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, tags=None, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass for training or inference.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input token indices.\n",
    "            tags (Tensor, optional): NER tag indices for training.\n",
    "            mask (Tensor, optional): Mask for padding.\n",
    "\n",
    "        Returns:\n",
    "            If tags is provided: loss (Tensor).\n",
    "            Else: decoded tag sequences (List[List[int]]).\n",
    "        Steps:\n",
    "            1. Look up embeddings for input token indices.\n",
    "            2. Pass embeddings through the BiLSTM to get contextualized token representations.\n",
    "            3. Use the linear layer to compute emission scores for each tag.\n",
    "            4. If training (tags provided):\n",
    "            - Compute CRF negative log-likelihood loss using emissions and true tags.\n",
    "            5. If inference (tags not provided):\n",
    "            - Use CRF to decode the most likely tag sequence for each sentence.\n",
    "            6. Return:\n",
    "            - Loss during training\n",
    "            - Decoded tag sequences during inference\n",
    "        \"\"\"\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, _ = self.bilstm(embeds)\n",
    "        emissions = self.hidden2tag(lstm_out)\n",
    "        if tags is not None:\n",
    "            loss = -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "            return loss\n",
    "        else:\n",
    "            return self.crf.decode(emissions, mask=mask)\n",
    "\n",
    "# -----------------------\n",
    "# 6. Hyperparameters\n",
    "# -----------------------\n",
    "embedding_dim = ft_model.vector_size\n",
    "hidden_dim = 128\n",
    "vocab_size = len(vocab)\n",
    "tagset_size = len(ner_tag_to_ix)\n",
    "batch_size = 32\n",
    "n_epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "# -----------------------\n",
    "# 7. DataLoader\n",
    "# -----------------------\n",
    "dataset = NERDataset(sentences, labels, vocab, ner_tag_to_ix)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# -----------------------\n",
    "# 8. Initialize model\n",
    "# -----------------------\n",
    "model = BiLSTM_CRF(vocab_size, embedding_dim, hidden_dim, tagset_size, ft_model)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# -----------------------\n",
    "# 9. Training\n",
    "# -----------------------\n",
    "start_time = time.time()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X, y in loader:\n",
    "        mask = (X != vocab[\"<PAD>\"])\n",
    "        optimizer.zero_grad() # Clears old gradients before computing new ones.\n",
    "        loss = model(X, tags=y, mask=mask)\n",
    "        loss.backward()\n",
    "        optimizer.step() # Applies gradient descent to update model parameters\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch}/{n_epochs}, Loss: {total_loss:.4f}\")\n",
    "print(f\"Training completed in {time.time() - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea44de96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as bilstm_crf_fasttext_epoch10.pth\n",
      "NER Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-DATE     0.9874    0.9846    0.9860     10549\n",
      "       B-LOC     0.9910    0.9838    0.9874     43951\n",
      "      B-TIME     0.9774    0.9730    0.9752      2263\n",
      "      I-DATE     0.9866    0.9796    0.9831     17095\n",
      "       I-LOC     0.9787    0.9812    0.9799     31973\n",
      "      I-TIME     0.9763    0.9763    0.9763      2872\n",
      "           O     0.9992    0.9994    0.9993   1983478\n",
      "\n",
      "    accuracy                         0.9985   2092181\n",
      "   macro avg     0.9852    0.9826    0.9839   2092181\n",
      "weighted avg     0.9985    0.9985    0.9985   2092181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 10. Save model\n",
    "# -----------------------\n",
    "torch.save(model.state_dict(), \"bilstm_crf_fasttext_epoch10.pth\")\n",
    "print(\"Model saved as bilstm_crf_fasttext_epoch10.pth\")\n",
    "\n",
    "# -----------------------\n",
    "# 11. Evaluation\n",
    "# -----------------------\n",
    "model.eval()\n",
    "all_true, all_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for X, y in loader:\n",
    "        mask = (X != vocab[\"<PAD>\"])\n",
    "        preds = model(X, mask=mask)\n",
    "        for i in range(len(preds)):\n",
    "            length = mask[i].sum().item()\n",
    "            all_pred.extend([id2tag[p] for p in preds[i][:length]])\n",
    "            all_true.extend([id2tag[t.item()] for t in y[i][:length]])\n",
    "\n",
    "print(\"NER Classification Report:\")\n",
    "print(classification_report(all_true, all_pred, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea927c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-DATE     0.9570    0.9417    0.9493      2744\n",
      "       B-LOC     0.9094    0.8910    0.9001     10967\n",
      "      B-TIME     0.9479    0.9465    0.9472       635\n",
      "      I-DATE     0.9687    0.9500    0.9592      4361\n",
      "       I-LOC     0.8443    0.8362    0.8403      8158\n",
      "      I-TIME     0.9146    0.9530    0.9334       809\n",
      "           O     0.9946    0.9954    0.9950    500371\n",
      "\n",
      "    accuracy                         0.9900    528045\n",
      "   macro avg     0.9338    0.9305    0.9321    528045\n",
      "weighted avg     0.9899    0.9900    0.9899    528045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 1. Load test set\n",
    "# -----------------------\n",
    "test_sentences, test_labels = load_conll(\"ner_20test.conll\")  \n",
    "test_dataset = NERDataset(test_sentences, test_labels, vocab, ner_tag_to_ix)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "# -----------------------\n",
    "# 11. Evaluation\n",
    "# -----------------------\n",
    "model.eval() # Switches the model to evaluation mode, \n",
    "all_true, all_pred = [], []\n",
    "with torch.no_grad(): # No gradients are computed\n",
    "    for X, y in test_loader: # for test\n",
    "        mask = (X != vocab[\"<PAD>\"])\n",
    "        preds = model(X, mask=mask)\n",
    "        for i in range(len(preds)):\n",
    "            length = mask[i].sum().item()\n",
    "            all_pred.extend([id2tag[p] for p in preds[i][:length]])\n",
    "            all_true.extend([id2tag[t.item()] for t in y[i][:length]])\n",
    "\n",
    "print(\"NER Classification Report:\")\n",
    "print(classification_report(all_true, all_pred, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "639faabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seqeval NER Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE     0.9470    0.9031    0.9246      2829\n",
      "         LOC     0.8772    0.8585    0.8678     11374\n",
      "        TIME     0.8775    0.8378    0.8571       641\n",
      "\n",
      "   micro avg     0.8903    0.8661    0.8780     14844\n",
      "   macro avg     0.9005    0.8665    0.8832     14844\n",
      "weighted avg     0.8905    0.8661    0.8781     14844\n",
      "\n",
      "F1-score: 0.8780304582394318\n",
      "Accuracy: 0.9902148491132384\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 1. Load test set\n",
    "# -----------------------\n",
    "test_sentences, test_labels = load_conll(\"ner_20test.conll\")  \n",
    "test_dataset = NERDataset(test_sentences, test_labels, vocab, ner_tag_to_ix)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "\n",
    "# -----------------------\n",
    "# 2. Evaluation with seqeval\n",
    "# -----------------------\n",
    "from seqeval.metrics import classification_report as seq_classification_report\n",
    "from seqeval.metrics import f1_score, accuracy_score\n",
    "\n",
    "model.eval()\n",
    "all_true, all_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        mask = (X != vocab[\"<PAD>\"])\n",
    "        preds = model(X, mask=mask)\n",
    "        for i in range(len(preds)):\n",
    "            length = mask[i].sum().item()\n",
    "            pred_tags = [id2tag[p] for p in preds[i][:length]]\n",
    "            true_tags = [id2tag[t.item()] for t in y[i][:length]]\n",
    "            all_pred.append(pred_tags)\n",
    "            all_true.append(true_tags)\n",
    "\n",
    "print(\"Seqeval NER Classification Report on Test Set:\")\n",
    "print(seq_classification_report(all_true, all_pred, digits=4))\n",
    "print(\"F1-score:\", f1_score(all_true, all_pred))\n",
    "print(\"Accuracy:\", accuracy_score(all_true, all_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0393d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tuned_BiLSTM_CRF(nn.Module):\n",
    "    \"\"\"\n",
    "    Tuned BiLSTM-CRF model with dropout and multiple LSTM layers.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of vocabulary.\n",
    "        embedding_dim (int): Dimension of embeddings.\n",
    "        hidden_dim (int): Hidden size of LSTM.\n",
    "        tagset_size (int): Number of NER tags.\n",
    "        ft_model (KeyedVectors): Pretrained FastText embeddings.\n",
    "        dropout (float): Dropout rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, tagset_size, ft_model, dropout=0.2):\n",
    "        super(tuned_BiLSTM_CRF, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # Load FastText embeddings\n",
    "        emb_weights = np.zeros((vocab_size, embedding_dim))\n",
    "        for w, idx in vocab.items():\n",
    "            if w in ft_model.wv:\n",
    "                emb_weights[idx] = ft_model.wv[w]\n",
    "            else:\n",
    "                emb_weights[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "        self.embedding.weight.data.copy_(torch.tensor(emb_weights, dtype=torch.float32))\n",
    "\n",
    "        self.bilstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim // 2,\n",
    "            num_layers=2,              # 2 layers\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout              # dropout between layers\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.crf = CRF(tagset_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x, tags=None, mask=None):\n",
    "        \"\"\"\n",
    "        Forward pass for training or inference.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input token indices.\n",
    "            tags (Tensor, optional): NER tag indices for training.\n",
    "            mask (Tensor, optional): Mask for padding.\n",
    "\n",
    "        Returns:\n",
    "            If tags is provided: loss (Tensor).\n",
    "            Else: decoded tag sequences (List[List[int]]).\n",
    "        \"\"\"\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, _ = self.bilstm(embeds)\n",
    "        lstm_out = self.dropout(lstm_out)        # üîß dropout before linear\n",
    "        emissions = self.hidden2tag(lstm_out)\n",
    "        if tags is not None:\n",
    "            loss = -self.crf(emissions, tags, mask=mask, reduction='mean')\n",
    "            return loss\n",
    "        else:\n",
    "            return self.crf.decode(emissions, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b199645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 3537.0331\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE     0.8848    0.8918    0.8883      1128\n",
      "         LOC     0.8506    0.7972    0.8230      4591\n",
      "        TIME     0.7923    0.8408    0.8158       245\n",
      "\n",
      "   micro avg     0.8547    0.8169    0.8354      5964\n",
      "   macro avg     0.8426    0.8433    0.8424      5964\n",
      "weighted avg     0.8546    0.8169    0.8351      5964\n",
      "\n",
      "Epoch 2/5, Train Loss: 1363.0186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE     0.9217    0.9184    0.9201      1128\n",
      "         LOC     0.8789    0.8271    0.8522      4591\n",
      "        TIME     0.8024    0.8122    0.8073       245\n",
      "\n",
      "   micro avg     0.8840    0.8437    0.8634      5964\n",
      "   macro avg     0.8677    0.8526    0.8599      5964\n",
      "weighted avg     0.8839    0.8437    0.8632      5964\n",
      "\n",
      "Epoch 3/5, Train Loss: 1006.4389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE     0.9517    0.9078    0.9292      1128\n",
      "         LOC     0.8684    0.8656    0.8670      4591\n",
      "        TIME     0.8797    0.8653    0.8724       245\n",
      "\n",
      "   micro avg     0.8841    0.8736    0.8788      5964\n",
      "   macro avg     0.8999    0.8796    0.8896      5964\n",
      "weighted avg     0.8846    0.8736    0.8790      5964\n",
      "\n",
      "Epoch 4/5, Train Loss: 812.3388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE     0.9255    0.9246    0.9251      1128\n",
      "         LOC     0.8794    0.8658    0.8726      4591\n",
      "        TIME     0.8415    0.8449    0.8432       245\n",
      "\n",
      "   micro avg     0.8866    0.8761    0.8813      5964\n",
      "   macro avg     0.8821    0.8785    0.8803      5964\n",
      "weighted avg     0.8866    0.8761    0.8813      5964\n",
      "\n",
      "Epoch 5/5, Train Loss: 671.3236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE     0.9208    0.9273    0.9240      1128\n",
      "         LOC     0.8780    0.8634    0.8706      4591\n",
      "        TIME     0.8531    0.8531    0.8531       245\n",
      "\n",
      "   micro avg     0.8852    0.8751    0.8801      5964\n",
      "   macro avg     0.8839    0.8813    0.8826      5964\n",
      "weighted avg     0.8850    0.8751    0.8800      5964\n",
      "\n",
      "Training completed in 4575.40 seconds\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "\n",
    "train_sents, val_sents, train_labels, val_labels = train_test_split(\n",
    "    sentences, labels, test_size=0.1, random_state=42\n",
    ") # train 90% / val 10%\n",
    "\n",
    "train_dataset = NERDataset(train_sents, train_labels, vocab, ner_tag_to_ix)\n",
    "val_dataset = NERDataset(val_sents, val_labels, vocab, ner_tag_to_ix)\n",
    "\n",
    "embedding_dim = ft_model.vector_size\n",
    "vocab_size = len(vocab)\n",
    "tagset_size = len(ner_tag_to_ix)\n",
    "batch_size = 32\n",
    "n_epochs = 5\n",
    "lr = 0.001\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "tuned_model = tuned_BiLSTM_CRF(vocab_size, embedding_dim, hidden_dim=256,  # üîß larger hidden_dim\n",
    "                   tagset_size=tagset_size, ft_model=ft_model, dropout=0.2)\n",
    "\n",
    "optimizer = optim.Adam(tuned_model.parameters(), lr=lr)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, factor=0.5)\n",
    "\n",
    "id2tag = {v: k for k, v in ner_tag_to_ix.items()}\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate a NER model and print classification report.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained NER model.\n",
    "        loader (DataLoader): DataLoader for evaluation data.\n",
    "\n",
    "    Returns:\n",
    "        float: F1 score of the predictions.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_true, all_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            mask = (X != vocab[\"<PAD>\"])\n",
    "            preds = model(X, mask=mask)\n",
    "\n",
    "            # Convert ids ‚Üí tags\n",
    "            for true_seq, pred_seq, m in zip(y.tolist(), preds, mask.tolist()):\n",
    "                true_tags = [id2tag[t] for t, mk in zip(true_seq, m) if mk]\n",
    "                pred_tags = [id2tag[t] for t in pred_seq]\n",
    "                all_true.append(true_tags)\n",
    "                all_pred.append(pred_tags)\n",
    "\n",
    "    f1 = f1_score(all_true, all_pred)\n",
    "    print(classification_report(all_true, all_pred, digits=4))\n",
    "    return f1\n",
    "\n",
    "# -----------------------\n",
    "# Training Loop\n",
    "# -----------------------\n",
    "start_time = time.time()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    tuned_model.train()\n",
    "    total_loss = 0\n",
    "    for X, y in train_loader:\n",
    "        mask = (X != vocab[\"<PAD>\"])\n",
    "        optimizer.zero_grad()\n",
    "        loss = tuned_model(X, tags=y, mask=mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch}/{n_epochs}, Train Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    f1 = evaluate(tuned_model, val_loader)\n",
    "\n",
    "    # LR scheduling\n",
    "    scheduler.step(f1)\n",
    "print(f\"Training completed in {time.time() - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f774b956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seqeval NER Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        DATE     0.9265    0.9226    0.9245      2829\n",
      "         LOC     0.8867    0.8538    0.8699     11374\n",
      "        TIME     0.8451    0.8424    0.8438       641\n",
      "\n",
      "   micro avg     0.8926    0.8664    0.8793     14844\n",
      "   macro avg     0.8861    0.8729    0.8794     14844\n",
      "weighted avg     0.8925    0.8664    0.8792     14844\n",
      "\n",
      "F1-score: 0.8793244906331191\n",
      "Accuracy: 0.9902110615572537\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 1. Load test set\n",
    "# -----------------------\n",
    "test_sentences, test_labels = load_conll(\"ner_20test.conll\")  \n",
    "test_dataset = NERDataset(test_sentences, test_labels, vocab, ner_tag_to_ix)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "\n",
    "# -----------------------\n",
    "# 2. Evaluation with seqeval\n",
    "# -----------------------\n",
    "from seqeval.metrics import classification_report as seq_classification_report\n",
    "from seqeval.metrics import f1_score, accuracy_score\n",
    "\n",
    "tuned_model.eval()\n",
    "all_true, all_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        mask = (X != vocab[\"<PAD>\"])\n",
    "        preds = tuned_model(X, mask=mask)\n",
    "        for i in range(len(preds)):\n",
    "            length = mask[i].sum().item()\n",
    "            pred_tags = [id2tag[p] for p in preds[i][:length]]\n",
    "            true_tags = [id2tag[t.item()] for t in y[i][:length]]\n",
    "            all_pred.append(pred_tags)\n",
    "            all_true.append(true_tags)\n",
    "\n",
    "print(\"Seqeval NER Classification Report on Test Set:\")\n",
    "print(seq_classification_report(all_true, all_pred, digits=4))\n",
    "print(\"F1-score:\", f1_score(all_true, all_pred))\n",
    "print(\"Accuracy:\", accuracy_score(all_true, all_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc75c68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-DATE     0.9488    0.9457    0.9473      2744\n",
      "       B-LOC     0.9212    0.8885    0.9046     10967\n",
      "      B-TIME     0.9407    0.9244    0.9325       635\n",
      "      I-DATE     0.9424    0.9688    0.9555      4361\n",
      "       I-LOC     0.8549    0.8335    0.8441      8158\n",
      "      I-TIME     0.8948    0.9567    0.9247       809\n",
      "           O     0.9947    0.9956    0.9951    500371\n",
      "\n",
      "    accuracy                         0.9902    528045\n",
      "   macro avg     0.9282    0.9305    0.9291    528045\n",
      "weighted avg     0.9901    0.9902    0.9902    528045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------\n",
    "# 11. Evaluation\n",
    "# -----------------------\n",
    "from sklearn.metrics import classification_report\n",
    "tuned_model.eval()\n",
    "all_true, all_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader: # for test\n",
    "        mask = (X != vocab[\"<PAD>\"])\n",
    "        preds = tuned_model(X, mask=mask)\n",
    "        for i in range(len(preds)):\n",
    "            length = mask[i].sum().item()\n",
    "            all_pred.extend([id2tag[p] for p in preds[i][:length]])\n",
    "            all_true.extend([id2tag[t.item()] for t in y[i][:length]])\n",
    "\n",
    "print(\"NER Classification Report:\")\n",
    "print(classification_report(all_true, all_pred, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b91db81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
