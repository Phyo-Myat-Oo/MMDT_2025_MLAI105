{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f37a58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thant\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\thant\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.05  val_macro_f1=0.6431\n",
      "C=0.1   val_macro_f1=0.6745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thant\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\thant\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.2   val_macro_f1=0.6892\n",
      "C=0.5   val_macro_f1=0.7151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thant\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1.0   val_macro_f1=0.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thant\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=2.0   val_macro_f1=0.6746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thant\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=5.0   val_macro_f1=0.6693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thant\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"test_accuracy\": 0.7597765363128491,\n",
      "  \"test_macro_f1\": 0.6297132751690375,\n",
      "  \"n_train\": 833,\n",
      "  \"n_val\": 178,\n",
      "  \"n_test\": 179,\n",
      "  \"labels\": [\n",
      "    \"1\",\n",
      "    \"2\",\n",
      "    \"3\"\n",
      "  ],\n",
      "  \"best_C\": 0.5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "CPU-optimized Logistic Regression text classifier (TF-IDF + multinomial LR)\n",
    "\n",
    "Matches DistilBERT script conventions:\n",
    "- Reads: out/alerts_pseudo.csv  (columns: Pseudo_Description, Priority_Level)\n",
    "- Same stratified 70/15/15 split + deterministic label encoding\n",
    "- Class imbalance handling (class_weight='balanced')\n",
    "- Simple hyperparam sweep on C using the validation set (macro-F1)\n",
    "- Saves: metrics JSON, confusion matrix CSV/PNG, curves PNG, label map\n",
    "- Fast on CPU; no extra deps beyond scikit-learn, numpy, pandas, matplotlib\n",
    "\n",
    "Run:\n",
    "    python train_logreg_text.py\n",
    "\"\"\"\n",
    "\n",
    "import os, json, math, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ---------------- Hard-coded settings ----------------\n",
    "in_csv = \"out/alerts_pseudo.csv\"      # <--- change if needed\n",
    "text_col = \"Pseudo_Description\"\n",
    "label_col = \"Priority_Level\"\n",
    "out_dir = Path(\"artifacts/priority_model_lr\")\n",
    "\n",
    "# Vectorizer settings (good defaults for alert text)\n",
    "tfidf_params = dict(\n",
    "    lowercase=True,\n",
    "    strip_accents=\"unicode\",\n",
    "    analyzer=\"word\",\n",
    "    ngram_range=(1, 2),   # unigrams + bigrams\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "# Logistic Regression settings\n",
    "# We'll sweep over C values on the validation set to pick best macro-F1.\n",
    "C_grid = [0.05, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0]\n",
    "max_iter = 2000\n",
    "penalty = \"l2\"\n",
    "solver = \"saga\"  # supports multinomial + class_weight\n",
    "class_weight = \"balanced\"\n",
    "seed = 42\n",
    "# -----------------------------------------------------\n",
    "\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    s = \"\" if pd.isna(s) else str(s)\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "\n",
    "def split_stratified(texts, y, seed=42):\n",
    "    X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "        texts, y, test_size=0.30, random_state=seed, stratify=y\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_tmp, y_tmp, test_size=0.50, random_state=seed, stratify=y_tmp\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return float((y_true == y_pred).mean()) if len(y_true) else 0.0\n",
    "\n",
    "\n",
    "def per_class_metrics(y_true, y_pred, n_classes):\n",
    "    metrics = {}\n",
    "    pr_list, rc_list, f1_list = [], [], []\n",
    "    for c in range(n_classes):\n",
    "        tp = int(((y_true == c) & (y_pred == c)).sum())\n",
    "        fp = int(((y_true != c) & (y_pred == c)).sum())\n",
    "        fn = int(((y_true == c) & (y_pred != c)).sum())\n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        rec  = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1   = (2 * prec * rec) / (prec + rec) if (prec + rec) > 0 else 0.0\n",
    "        metrics[c] = {\"precision\": prec, \"recall\": rec, \"f1\": f1, \"support\": int((y_true == c).sum())}\n",
    "        pr_list.append(prec); rc_list.append(rec); f1_list.append(f1)\n",
    "    macro = {\n",
    "        \"precision\": float(np.mean(pr_list)) if pr_list else 0.0,\n",
    "        \"recall\": float(np.mean(rc_list)) if rc_list else 0.0,\n",
    "        \"f1\": float(np.mean(f1_list)) if f1_list else 0.0,\n",
    "    }\n",
    "    return metrics, macro\n",
    "\n",
    "\n",
    "def confusion_matrix_counts(y_true, y_pred, n_classes):\n",
    "    cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[int(t), int(p)] += 1\n",
    "    return cm\n",
    "\n",
    "\n",
    "def main():\n",
    "    np.random.seed(seed)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ---- Data\n",
    "    df = pd.read_csv(in_csv)\n",
    "    need = {text_col, label_col}\n",
    "    missing = need - set(df.columns)\n",
    "    if missing:\n",
    "        raise SystemExit(f\"Missing columns: {missing}\")\n",
    "\n",
    "    df = df[[text_col, label_col]].dropna().drop_duplicates()\n",
    "    df[text_col] = df[text_col].apply(clean_text)\n",
    "    df = df[df[text_col].str.len() > 0].reset_index(drop=True)\n",
    "\n",
    "    # Label encoding (deterministic, lexicographic order like the BERT script)\n",
    "    labels_raw = df[label_col].astype(str).values\n",
    "    classes_sorted = sorted(np.unique(labels_raw).tolist())\n",
    "    label2id = {lbl: i for i, lbl in enumerate(classes_sorted)}\n",
    "    id2label = {i: lbl for lbl, i in label2id.items()}\n",
    "    y = np.array([label2id[s] for s in labels_raw], dtype=np.int64)\n",
    "    num_classes = len(classes_sorted)\n",
    "\n",
    "    # Persist label map\n",
    "    (out_dir / \"label_map.json\").write_text(\n",
    "        json.dumps({\"label2id\": label2id, \"id2label\": {int(k): v for k, v in id2label.items()}}, indent=2),\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "    # Split\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_stratified(df[text_col].tolist(), y, seed=seed)\n",
    "\n",
    "    # ---- Model selection on validation set (sweep C)\n",
    "    val_scores = []\n",
    "    best = {\"C\": None, \"val_macro_f1\": -1.0, \"model\": None}\n",
    "\n",
    "    for C in C_grid:\n",
    "        pipe = Pipeline([\n",
    "            (\"tfidf\", TfidfVectorizer(**tfidf_params)),\n",
    "            (\"clf\", LogisticRegression(\n",
    "                C=C,\n",
    "                penalty=penalty,\n",
    "                solver=solver,\n",
    "                class_weight=class_weight,\n",
    "                max_iter=max_iter,\n",
    "                n_jobs=os.cpu_count() or 1,\n",
    "                random_state=seed,\n",
    "                multi_class=\"multinomial\"\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "        pipe.fit(X_train, y_train)\n",
    "        val_pred = pipe.predict(X_val)\n",
    "        val_macro_f1 = f1_score(y_val, val_pred, average=\"macro\")\n",
    "        val_scores.append((C, val_macro_f1))\n",
    "\n",
    "        if val_macro_f1 > best[\"val_macro_f1\"]:\n",
    "            best.update({\"C\": C, \"val_macro_f1\": float(val_macro_f1), \"model\": pipe})\n",
    "\n",
    "        print(f\"C={C:<4}  val_macro_f1={val_macro_f1:.4f}\")\n",
    "\n",
    "    # Save the C-sweep curve\n",
    "    if val_scores:\n",
    "        Cs = [c for c, _ in val_scores]\n",
    "        f1s = [s for _, s in val_scores]\n",
    "        fig = plt.figure(figsize=(7, 4.5))\n",
    "        plt.plot(Cs, f1s, marker=\"o\", label=\"val_macro_f1\")\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlabel(\"C (inverse regularization) [log scale]\")\n",
    "        plt.ylabel(\"Macro-F1 (validation)\")\n",
    "        plt.title(\"LR model selection on validation set\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(out_dir / \"val_c_sweep.png\", dpi=160)\n",
    "        plt.close(fig)\n",
    "\n",
    "    if best[\"model\"] is None:\n",
    "        raise SystemExit(\"No model trained during C sweep.\")\n",
    "\n",
    "    # ---- (Optional) Refit on Train+Val using best C, evaluate on Test\n",
    "    X_trval = X_train + X_val\n",
    "    y_trval = np.concatenate([y_train, y_val])\n",
    "\n",
    "    final_pipe = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(**tfidf_params)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            C=best[\"C\"],\n",
    "            penalty=penalty,\n",
    "            solver=solver,\n",
    "            class_weight=class_weight,\n",
    "            max_iter=max_iter,\n",
    "            n_jobs=os.cpu_count() or 1,\n",
    "            random_state=seed,\n",
    "            multi_class=\"multinomial\"\n",
    "        ))\n",
    "    ])\n",
    "    final_pipe.fit(X_trval, y_trval)\n",
    "\n",
    "    # ---- Test evaluation\n",
    "    test_pred = final_pipe.predict(X_test)\n",
    "    acc = accuracy(y_test, test_pred)\n",
    "    per_class, macro = per_class_metrics(y_test, test_pred, n_classes=num_classes)\n",
    "    cm = confusion_matrix_counts(y_test, test_pred, n_classes=num_classes)\n",
    "\n",
    "    # ---- Save reports\n",
    "    rep = {\n",
    "        \"accuracy\": float(acc),\n",
    "        \"macro\": macro,\n",
    "        \"per_class\": {id2label[i]: per_class[i] for i in range(num_classes)},\n",
    "        \"best_C\": float(best[\"C\"]),\n",
    "        \"val_macro_f1_at_best_C\": float(best[\"val_macro_f1\"])\n",
    "    }\n",
    "    (out_dir / \"test_classification_report.json\").write_text(json.dumps(rep, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    pd.DataFrame(\n",
    "        cm,\n",
    "        index=[id2label[i] for i in range(num_classes)],\n",
    "        columns=[id2label[i] for i in range(num_classes)]\n",
    "    ).to_csv(out_dir / \"test_confusion_matrix.csv\", index=True)\n",
    "\n",
    "    summary = {\n",
    "        \"test_accuracy\": float(acc),\n",
    "        \"test_macro_f1\": float(macro[\"f1\"]),\n",
    "        \"n_train\": int(len(X_train)),\n",
    "        \"n_val\": int(len(X_val)),\n",
    "        \"n_test\": int(len(X_test)),\n",
    "        \"labels\": [id2label[i] for i in range(num_classes)],\n",
    "        \"best_C\": float(best[\"C\"])\n",
    "    }\n",
    "    (out_dir / \"summary.json\").write_text(json.dumps(summary, indent=2), encoding=\"utf-8\")\n",
    "    print(json.dumps(summary, indent=2))\n",
    "\n",
    "    # ---- Confusion matrix plot (row-normalized)\n",
    "    cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True).clip(min=1.0)\n",
    "    fig = plt.figure(figsize=(6 + 0.3*num_classes, 5 + 0.3*num_classes))\n",
    "    plt.imshow(cm_norm, aspect=\"auto\")\n",
    "    ticks = np.arange(num_classes)\n",
    "    labels = [id2label[i] for i in ticks]\n",
    "    plt.xticks(ticks, labels, rotation=45, ha=\"right\")\n",
    "    plt.yticks(ticks, labels)\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix (row-normalized) — Logistic Regression\")\n",
    "    for i in range(cm_norm.shape[0]):\n",
    "        for j in range(cm_norm.shape[1]):\n",
    "            plt.text(j, i, f\"{cm_norm[i, j]:.2f}\", ha=\"center\", va=\"center\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_dir / \"confusion_matrix.png\", dpi=160)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # ---- Persist vectorizer + model (sklearn pipeline)\n",
    "    # Joblib is standard for sklearn persistence\n",
    "    try:\n",
    "        import joblib\n",
    "        joblib.dump(final_pipe, out_dir / \"model.joblib\", compress=3)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: failed to save model.joblib due to: {e}\")\n",
    "\n",
    "    # Also persist the tf-idf vocabulary for transparency (optional)\n",
    "    try:\n",
    "        tfidf = final_pipe.named_steps[\"tfidf\"]\n",
    "        vocab = {k: int(v) for k, v in tfidf.vocabulary_.items()}\n",
    "        (out_dir / \"tfidf_vocab.json\").write_text(json.dumps(vocab), encoding=\"utf-8\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
