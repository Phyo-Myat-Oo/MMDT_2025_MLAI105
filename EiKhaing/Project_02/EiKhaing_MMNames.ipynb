{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl for reading excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_cleaning as dc\n",
    "dc.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in our pipeline involves loading the data into a pandas DataFrame. This is accomplished using the pandas library, which is imported at the beginning of the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/MMNames_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ellen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ellen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ellen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13659, 13003) (5854, 13003)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Prepare the data\n",
    "import data_preprocessing as dp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = dp.preprocess_category(df,'SR_Name') # Convert State/Region as categorial code\n",
    "df = dp.preprocess_onehot(df,'name') # Conver Town/Village as one hot encoding categorail code\n",
    "\n",
    "y = df['SR_Name'].values \n",
    "X = df.drop(columns=['SR_Name']).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SR_Name  name_(Du) Chee Yar Tan  name_(Du) Nyaung Pin Gyi  \\\n",
      "0            0                   False                     False   \n",
      "1            0                   False                     False   \n",
      "2            0                   False                     False   \n",
      "3            0                   False                     False   \n",
      "4            0                   False                     False   \n",
      "...        ...                     ...                       ...   \n",
      "19508       12                   False                     False   \n",
      "19509        6                   False                     False   \n",
      "19510       15                   False                     False   \n",
      "19511       11                   False                     False   \n",
      "19512       11                   False                     False   \n",
      "\n",
      "       name_(Kyun Nyo Gyi) Kyun Hteik  name_(Pa) Nyaung Pin Gyi  \\\n",
      "0                               False                     False   \n",
      "1                               False                     False   \n",
      "2                               False                     False   \n",
      "3                               False                     False   \n",
      "4                               False                     False   \n",
      "...                               ...                       ...   \n",
      "19508                           False                     False   \n",
      "19509                           False                     False   \n",
      "19510                           False                     False   \n",
      "19511                           False                     False   \n",
      "19512                           False                     False   \n",
      "\n",
      "       name_(Saing) Hpa Yar Kone  name_22-Maing  name_38-Maing Man Pying  \\\n",
      "0                          False          False                    False   \n",
      "1                          False          False                    False   \n",
      "2                          False          False                    False   \n",
      "3                          False          False                    False   \n",
      "4                          False          False                    False   \n",
      "...                          ...            ...                      ...   \n",
      "19508                      False          False                    False   \n",
      "19509                      False          False                    False   \n",
      "19510                      False          False                    False   \n",
      "19511                      False          False                    False   \n",
      "19512                      False          False                    False   \n",
      "\n",
      "       name_4 Maing Kan Thar  name_55 Maing  ...  name_Zokhua  name_Zongte  \\\n",
      "0                      False          False  ...        False        False   \n",
      "1                      False          False  ...        False        False   \n",
      "2                      False          False  ...        False        False   \n",
      "3                      False          False  ...        False        False   \n",
      "4                      False          False  ...        False        False   \n",
      "...                      ...            ...  ...          ...          ...   \n",
      "19508                  False          False  ...        False        False   \n",
      "19509                  False          False  ...        False        False   \n",
      "19510                  False          False  ...        False        False   \n",
      "19511                  False          False  ...        False        False   \n",
      "19512                  False          False  ...        False        False   \n",
      "\n",
      "       name_Zu Kaing  name_Zultu  name_Zwe Bar  name_Zwe Bar Kone Tan  \\\n",
      "0              False       False         False                  False   \n",
      "1              False       False         False                  False   \n",
      "2              False       False         False                  False   \n",
      "3              False       False         False                  False   \n",
      "4              False       False         False                  False   \n",
      "...              ...         ...           ...                    ...   \n",
      "19508          False       False         False                  False   \n",
      "19509          False       False         False                  False   \n",
      "19510          False       False         False                  False   \n",
      "19511          False       False         False                  False   \n",
      "19512          False       False         False                  False   \n",
      "\n",
      "       name_Zwe Htaw  name_Zwe Ka Lar  name_Zwe Ka Nar  name_Zwe Kaik  \n",
      "0              False            False            False          False  \n",
      "1              False            False            False          False  \n",
      "2              False            False            False          False  \n",
      "3              False            False            False          False  \n",
      "4              False            False            False          False  \n",
      "...              ...              ...              ...            ...  \n",
      "19508          False            False            False          False  \n",
      "19509          False            False            False          False  \n",
      "19510          False            False            False          False  \n",
      "19511          False            False            False          False  \n",
      "19512          False            False            False          False  \n",
      "\n",
      "[19513 rows x 13004 columns]\n"
     ]
    }
   ],
   "source": [
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build a NN model with TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_classification_model(input_shape, num_classes, params={}):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(shape=input_shape),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(8, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13003 18\n"
     ]
    }
   ],
   "source": [
    "#print(X_train.shape[1], len(df['SR_Name'].unique())) # Input = 13003, output = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 119.02 seconds\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create and train the model\n",
    "import time\n",
    "model = create_classification_model(input_shape=[X_train.shape[1]],num_classes=len(df['SR_Name'].unique()), )\n",
    "start_time = time.time()  # to calcuate the training time\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, \n",
    "                    validation_data=(X_test, y_test), verbose=0)\n",
    "training_time = time.time() - start_time # to calcuate the training time\n",
    "print(f\"Training time: {training_time:.2f} seconds\")\n",
    "# model.fit() returns a History object. history.history — a dictionary of loss and validation loss (and metrics if specified) for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">416,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">162</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │       \u001b[38;5;34m416,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │           \u001b[38;5;34m162\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,250,864</span> (4.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,250,864\u001b[0m (4.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">416,954</span> (1.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m416,954\u001b[0m (1.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">833,910</span> (3.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m833,910\u001b[0m (3.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Evaluate the model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=32, verbose=0) # batch_size = 32: processes 32 samples at a time for efficiency., verbose=0: disables output logs.\n",
    "y_pred = y_pred.argmax(axis=1)  # Converts probability outputs into actual class labels\n",
    "report = classification_report(y_test, y_pred, output_dict=True) # Compares predicted labels (y_pred) to true labels (y_test). output_dict=True: returns the report as a dictionary for easier DataFrame conversion.\n",
    "report_df = pd.DataFrame(report).round(2).transpose() # Converts the report dictionary into a clean, rounded DataFrame.\n",
    "report_df.to_csv('./data/cls_report_test.csv', index=False)\n",
    "\n",
    "y_pred = model.predict(X_train, batch_size=32, verbose=0)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "report = classification_report(y_train, y_pred, output_dict=True)\n",
    "report_df = pd.DataFrame(report).round(2).transpose()\n",
    "report_df.to_csv('./data/cls_report_train.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMDT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
